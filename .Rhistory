hist(x,dist)
hist(x:dist)
save.image("C:\\Users\\Henry\\Documents\\Revolution\\first-workspace")
clr
clear
clear()
clr()
source("oddcount.R")
source("oddcount.R")
oddcount(c(1,3,5))
oddcount(1,2,3,4,5)
l<-list(2,"abc")
l
hist(cars$distance)
cars
hist(cars$dist)
hist(cars$speed)
str(cars)
save.image("C:\\Users\\Henry\\Documents\\Revolution\\learning")
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
update.packages(ask='graphics')
utils:::menuInstallLocal()
load?
scan
save.image("C:\\Users\\Henry\\Documents\\Projects\\Titanic\\Titanic")
scan train.csv
help("scan")
scan "train.csv"
help("scan")
scan("
train.csv")
scan("C:\\Users\\Henry\\Documents\\Projects\\Titanic\\train.csv")
help("scan")
getwd()
setwd(C:/Users/Henry/Documents/Projects/Titanic")
help("setwd")
setwd(C:/Users/Henry/Documents/Projects/Titanic)
setwd(C:\\Users\\Henry\\Documents\\Projects\\Titanic)
setwd(
)
setwd("C:/Users/Henry/Documents/Projects/Titanic")
getwd
getwd()
scan(
"train.csv")
help("scan")
cat(file="train.csv",skip=1,sep=",")
ls()
l
q
x
Help(read.table)
read.table(help)
read.table("train.csv")
help("read.table")
read.table("train.csv",header=TRUE, sep=",")
read.table("train.csv",header=TRUE, sep=",")
ls()
x
train<-read.table("train.csv",header=TRUE, sep=",")
train
save.image("C:\\Users\\Henry\\Documents\\Projects\\Titanic\\Titanic")
ls()
summary model
help.start()
summary(model$)
summary(model)
table
l
l
train
library(ggplot)
library(ggplot2)
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
update.packages(ask='graphics')
ggplot(train) + geom_histogram(aes(x=age), binwidth=5, fill="blue")
utils:::menuInstallPkgs()
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
ggplot(train) + geom_histogram(aes(x=age), binwidth=5, fill="blue")
ggplot(train) + geom_density(aes(x=age)) + scale_x_continuous
ggplot(train) + geom_density(aes(x=age))
summary(table$age)
summary(table)
summary(train$age)
train$age
train2 <- subset(train, (custdata$age >= 1))
train2 <- subset(train, (train$age >= 1))
cor(train2$age, train2$survived)
ggplot(train2,aes(x=age,y=survived))+geom_point()
ggplot(train2,aes(x=age,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
train2
train2
train2
train2
train2
ggplot(train2,aes(x=fare,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
corr(train2$age,train2$fare)
cor(train2$age,train2$fare)
help.cor
?help.cor
??help.cor
help.start()
summary(train2)
cor(train2$pclass,train2$fare)
ggplot(train2,aes(x=pclass,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2,aes(x=as.numeric(sex),y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2)+geom_bar(aes(x=sex,fill=survived))
ggplot(train2)+geom_bar(aes(x=survived,fill=sex))
ggplot(train2,aes(x=fare,y=as.numeric(sex)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2)+geom_bar(aes(x=fare,fill=sex))
num_f_survived <- count(train2,"sex")
count(train2,"sex")
count(train2,"sex","survived")
count(train2,"sex"=0)
count(train2,"sex"="male")
count(train2,"sex","survived")/count(train2,"sex")
195/259
88/448
ggplot(train2,aes(x=fare,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2,aes(x=fare,y=as.numeric(pclass)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2) + geom_bar(aes(x=pclass),fill="survived")
ggplot(train2) + geom_bar(aes(x=pclass),fill=survived)
ggplot(train2) + geom_bar(aes(x=pclass),fill=survived))
ggplot(train2) + geom_bar(aes(x=pclass,fill=survived))
ggplot(train2) + geom_bar(aes(x=survived,fill=pclass))
ggplot(train2) + geom_bar(aes(x=as.numeric(survived),fill=pclass))
ggplot(train2) + geom_bar(aes(x=pclass,fill=as.numeric(survived)))
ggplot(train2) + geom_bar(aes(x=as.factor(pclass),fill=as.numeric(survived)))
ggplot(train2) + geom_bar(aes(x=as.numeric(survived)as.factor(pclass)as.factor(pclass),fill=as.numeric(survived)))
ggplot(train2) + geom_bar(aes(x=as.numeric(survived),fill=as.factor(pclass)))
count(train2,"pclass","survived")/count(train2,"pclass")
count(train2,"pclass","survived")
121/(121+80+82)
ggplot(train2,aes(x=age,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2)+geom_bar(aes(x=as.factor(pclass),fill=survived),position="fill")
ggplot(train2)+geom_bar(aes(x=as.factor(pclass),fill=as.boolean(survived)),position="fill")
ggplot(train2)+geom_bar(aes(x=as.factor(pclass),fill=as.factor(survived)),position="fill")
ggplot(train2,aes(x=age,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
brks<-c(0,5,10,2,60,Inf)
train2$age_bin<-cut(train2$age,breaks=brks,include.lowest=T)
summary(train2$age_bin)
ggplot(train2,aes(x=age_bin,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
ggplot(train2)+geom_bar(aes(x=age_bin,fill=as.factor(survived)),position="fill")
ggplot(train2)+geom_bar(aes(x=age_bin,y=as.factor(pclass),fill=as.factor(survived)),position="fill")
ggplot(train2)+geom_bar(aes(x=age_bin,y=pclass,fill=as.factor(survived)),position="fill")
ggplot(train2)+geom_bar(aes(y=age_bin,x=pclass,fill=as.factor(survived)),position="fill")
ggplot(train2)+geom_bar(aes(x=age_bin,fill=as.factor(pclass)),position="fill")
ggplot(train2)+geom_bar(aes(x=age_bin,y=as.factor(pclass),fill=as.factor(survived)),position="fill")
ggplot(train2)+geom_bar(aes(x=age_bin,fill=as.factor(survived)),position="fill")
library('rpart')
?help rpart
help(rpart)
fit1<-rpart(survived ~ age_bin + rate + age,data=train2)
fit1<-rpart(survived ~ age_bin + fare + age,data=train2)
summary fit1
summary(fit1)
print.rpart(fit1)
print(fit1)
fit1<-rpart(survived ~ age_bin + as.factor(ppclass) + sex,data=train2)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex,data=train2)
print(fit1)
summary(train2)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + rate,data=train2)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + fare,data=train2)
print(fit1)
plot(fit2)
plot(fit1)
help(plot.rpart)
text(fit1,use.n=TRUE)
plot(fit,compress=TRUE)
plot(fit1,compress=TRUE)
text(fit1,use.n=TRUE)
plot(fit1,compress=TRUE,margin=5)
plot(fit1,margin=5)
text(fit1,use.n=TRUE)
plot(fit1,compress=TRUE,margin=1)
text(fit1,use.n=TRUE)
summary(train2)
ggplot(train2,aes(x=fare,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
summary(train2$parch)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + fare,data=train2)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + as.factor(sibsp) + as.factor(parch) + fare,data=train2)
print(fit1)
ggplot(train2,aes(x=parch,y=as.numeric(survived)))+geom_point(position=position_jitter(w=0.05,h=0.05))+geom_smooth()
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2)
print(fit1)
help(rpart)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2,model=class)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2,model="class")
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2,method="class")
print(fit1)
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2,method="exp")
fit1<-rpart(survived ~ age_bin + as.factor(pclass) + sex + sibsp + parch + fare,data=train2,method="anova")
print(fit1)
save.image("C:\\Users\\Henry\\Documents\\Projects\\Titanic\\titanic-131123.RData")
install.packages("cubist")
install.packages("Cubist")
library(Cubist)
install.packages("arules")
libary(arules)
library(arules)
head(rownames(a),3)
a<-available.packages()
head(rownames(a),3)
search()
find.packages(devtools)
find_rtools()
install.packages("devtools")
install.packages("R.matlab")
library(R.matlab)
set.seed(1)
rpois(5,2)
Ni <- rpois(50, lambda = 4); table(factor(Ni, 0:max(Ni)))
set.seed(1)
for i in 1:5 {
rpois(5,2)
}
for i = 1:5 {
for (i in 1:5) {
rpois(5,2)
}
set.seed(1)
for (i in 1:5) {
rpois(5,2)
}
set.seed(1)
for (i in 1:5) {
print(rpois(5,2))
}
dnorm(5,1,1)
dnorm(mean=1,sd=1)
dnorm(4,mean=1,sd=1)
pnorm(4,1,1)
rnorm(4,1,1)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
plot(x)
set.seed(10)
x <- rbinom(100, 10, 0.5)
e <- rnorm(100, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
source('~/.active-rstudio-document', echo=TRUE)
set.seed(10)
x <- rnorm(100, 10, 0.5)
e <- rnorm(100, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
source('~/.active-rstudio-document', echo=TRUE)
x <- rbinom(100, 100, 0.5)
plot(x)
source('~/.active-rstudio-document', echo=TRUE)
x <- rbinom(100, 10, 0.5)
plot(x)
e <- rnorm(100, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
plot(e)
plot(x,y)
load("~/Projects/Getting-Cleaning-Data/Project/project.RData")
load("~/Projects/Getting-Cleaning-Data/.RData")
load("~/Projects/Getting-Cleaning-Data/Project/wearable/.RData")
library(datasets)
data(airquality)
qplot(Wind,Ozone,data=airquality,facets= . ~ factor(Month))
install.packages('ggplot2')
library(ggplot2)
install.packages('colorspace')
library(ggplot2)
install.packages('scales')
library(ggplot2)
qplot(Wind,Ozone,data=airquality,facets= . ~ factor(Month))
install.packages('proto')
install.packages(c("DBI", "formatR", "gsubfn", "htmltools", "httr", "jsonlite", "labeling", "markdown", "mime", "R.utils", "RCurl", "swirl", "xlsxjars"))
install.packages("proto")
library(ggplot2)
qplot(Wind,Ozone,data=airquality,facets= . ~ factor(Month))
airquality<-transform(airquality,Month=factor(Month))
qplot(Wind,Ozone,data=airquality,facets=.~Month)
install.packages('gtable')
install.packages("gtable")
qplot(Wind,Ozone,data=airquality,facets=.~Month)
library(ggplot2)
qplot(Wind,Ozone,data=airquality,facets=.~Month)
ggplot(movies,aes(votes,rating))
data(movies)
ggplot(movies,aes(votes,rating))
qplot(votes,rating,data=movies)
qplot(votes,rating,data=movies,smooth="loess")
qplot(votes,rating,data=movies) + geom_smooth()
setwd("./GPR/Research-improve-opps-report")
setwd("E:\Research-improve-opps-report")
getwd
getwd()
installpackages("CodeDepends","Rgraphviz")
install.packages("CodeDepends","Rgraphviz")
install.packages("CodeDepends")
install.packages("caret")
library(caret)
library(ElemStatLearn)
library(caret)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
class(vowel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rForest <- train(y ~ .,method="rf",data=vowel.train)
rBoost <- train(y ~ .,method="gbm",data=vowel.train)
rBoost <- train(y ~ .,method="gbm",data=vowel.train,verbose=FALSE)
predRF <- predict(rForest,vowel.test)
predGBM <- predict(rBoost,vowel.test)
rForest$finalModel
confusionMatrix(predRF, vowel.test$y)
confusionMatrix(predGBM, vowel.test$y)
confusionMatrix(predRF,predGBM)
confusionMatrix(predGBM,predRF)
rBoost$finalModel
qplot(predRF,predGBM,colour=y,data=vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rForest <- train(y ~ .,method="rf",data=vowel.train)
rForest$finalModel
predRF <- predict(rForest,vowel.test)
confusionMatrix(predRF, vowel.test$y)
predGBM <- predict(rBoost,vowel.test)
rBoost <- train(y ~ .,method="gbm",data=vowel.train,verbose=FALSE)
predGBM <- predict(rBoost,vowel.test)
confusionMatrix(predGBM, vowel.test$y)
predDF <- data.frame(predRF,predGBM,y=vowel.test$y)
View(predDF)
predDF <- predDF[predDF$predRF==predDF$predGBM,]
predDF <- data.frame(predRF,predGBM,y=vowel.test$y)
predDF.agree <- predDF[predDF$predRF==predDF$predGBM,]
acc.agree <- nrow(predDF.agree[predDF.agree$predRF==predDF.agree$y,])
acc.agree <- nrow(predDF.agree[predDF.agree$predRF==predDF.agree$y,])/nrow(predDF)
acc.agree <- nrow(predDF.agree[predDF.agree$predRF==predDF.agree$y,])/nrow(predDF.agree)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelRF <- train(diagnosis ~ . ,method="rf",data=training)
modelRF$finalModel$accuracy
summary(modelRF$finalModel)
modelGBM <- train(diagnosis ~ .,method="gbm",data=training,verbose=FALSE)
modelLDA <- train(diagnosis ~ .,method="lda",data=training,verbose=FALSE)
predRF <- predict(modelRF,testing)
predGBM <- predict(modelGBM,testing)
predLDA <- predict(modelLDA,testing)
predComb <- data.frame(predRF,predGBM,predLDA,diagnosis = testing$diagnosis)
View(predComb)
accRF <- nrow(predComb[predComb$predRF==predComb$diagnosis,])/nrow(predComb)
accRF <- nrow(predComb[predComb$predGBM==predComb$diagnosis,])/nrow(predComb)
accRF <- nrow(predComb[predComb$predRF==predComb$diagnosis,])/nrow(predComb)
accGBM <- nrow(predComb[predComb$predGBM==predComb$diagnosis,])/nrow(predComb)
accLDA <- nrow(predComb[predComb$predLDA==predComb$diagnosis,])/nrow(predComb)
modelComb <- train(diagnosis ~ .,method="rf",data=predComb)
modelComb$finalModel
resultsComb <- predict(modelComb,data=testing)
resultsComb <- predict(modelComb,data=predComb)
resultsComb <- predict(modelComb,predComb)
confusioinMatrix(resultsComb,predComb$diagnosis)
confusionMatrix(resultsComb,predComb$diagnosis)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelRF <- train(diagnosis ~ . ,method="rf",data=training)
modelGBM <- train(diagnosis ~ .,method="gbm",data=training,verbose=FALSE)
View(predComb)
modelLDA <- train(diagnosis ~ .,method="lda",data=training,verbose=FALSE)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
modelRF <- train(diagnosis ~ . ,method="rf",data=training)
modelGBM <- train(diagnosis ~ .,method="gbm",data=training,verbose=FALSE)
modelLDA <- train(diagnosis ~ .,method="lda",data=training,verbose=FALSE)
modelLDAmanual <- lda(diagnosis ~ .,training)
predLDAman <- predict(modelLDAmanual,testing))$class
predLDAman <- predict(modelLDAmanual,testing)$class
predRF <- predict(modelRF,testing)
predGBM <- predict(modelGBM,testing)
predLDA <- predict(modelLDA,testing)
predComb <- data.frame(predRF,predGBM,predLDA,diagnosis = testing$diagnosis)
table(predLDA,predLDAman)
predGBM$accuracy
confusionMatrix(predRF,testing$diagnosis)
confusionMatrix(predRF,testing$diagnosis)$accuracy
confusionMatrix(predRF,testing$diagnosis)$pred
confusionMatrix(predRF,testing$diagnosis)
confusionMatrix(predGBM,testing$diagnosis)
confusionMatrix(predLDA,testing$diagnosis)
confusionMatrix(resultsComb,predComb$diagnosis)
modelComb <- train(diagnosis ~ .,method="rf",data=predComb)
resultsComb <- predict(modelComb,predComb)
confusionMatrix(resultsComb,predComb$diagnosis)
set.seed(62433)
modelRF <- train(diagnosis ~ . ,method="rf",data=training)
modelGBM <- train(diagnosis ~ .,method="gbm",data=training,verbose=FALSE)
modelLDA <- train(diagnosis ~ .,method="lda",data=training,verbose=FALSE)
modelLDAmanual <- lda(diagnosis ~ .,training)
predRF <- predict(modelRF,testing)
predGBM <- predict(modelGBM,testing)
predLDA <- predict(modelLDA,testing)
predLDAman <- predict(modelLDAmanual,testing)$class
predComb <- data.frame(predRF,predGBM,predLDA,diagnosis = testing$diagnosis)
table(predLDA,predLDAman)
modelComb <- train(diagnosis ~ .,method="rf",data=predComb)
resultsComb <- predict(modelComb,predComb)
accRF <- nrow(predComb[predComb$predRF==predComb$diagnosis,])/nrow(predComb)
accGBM <- nrow(predComb[predComb$predGBM==predComb$diagnosis,])/nrow(predComb)
accLDA <- nrow(predComb[predComb$predLDA==predComb$diagnosis,])/nrow(predComb)
confusionMatrix(resultsComb,predComb$diagnosis)
varImp(predComp)
varImp(predComn)
varImp(predComb)
varImp(modelComb)
getmethod(mean)
showmethod(mean)
getMethod(mean)
getMethod("mean")
getMethod("colSums")
getMethod("dgamma")
showMethods("mean")
showMethods("table")
showMethods("lm")
showMethods("sum")
getMethods("sum")
getMethod("sum")
getMethod("colSums")
getMethod("train")
getMethod("plot")
getMethods("plot")
getMethod("print")
showMethods("mean")
getS3Method("print")
getS3method("print")
source('~/Projects/Capstone/textprediction/tm-explore-v4.R', echo=TRUE)
object.size(sFreqTable3)
source('~/Projects/Capstone/textprediction/tm-explore-v4.R', echo=TRUE)
save.image("~/Projects/Capstone/textprediction/ngrams-by-50.RData")
source('~/Projects/Capstone/textprediction/tm-explore-v4.R', echo=TRUE)
save.image("~/Projects/Capstone/textprediction/ngrams-by-25.RData")
source('~/Projects/Capstone/textprediction/tm-explore-v4.R', echo=TRUE)
View(sFreqTable3)
save.image("~/Projects/Capstone/textprediction/ngrams-by-10.RData")
source('~/Projects/Capstone/textprediction/tm-explore-v4.R', echo=TRUE)
save.image("~/Projects/Capstone/textprediction/ngrams-all-words.RData")
load("~/Projects/Capstone/textprediction/ngrams-by-50.RData")
load("~/Projects/Capstone/textprediction/ngrams-all-words.RData")
obj.size(temp)
summary(termFreqTab)
termFreqTable
summary(termFreqTable)
View(temp)
remove(temp)
remove(corp)
remove(textASCII)
remove(red)
remove(l)
remove(i)
remove(totFreq)
save.image("~/Projects/Capstone/textprediction/bln-kernel.RData")
object.size(sFreqTable2)
object.size(sFreqTable3)
object.size(termFreqTable)
object.size(termFreqTable2)
object.size(termFreqTable3)
install.packages("bnlearn")
data(learning.test)
require("bnlearn")
require("ggplot2")
require("stringr")
require("plyr")
setwd("~/Projects/Capstone/textprediction")
data(learning.test)
res = empty.graph(names(learning.test))
modelstring(res) = "[A][C][F][B|A][D|A:C][E|B:F]"
plot(res)
learning.net
learning.test
learn.net = empty.graph(names(learning.test))
modelstring(learn.net) = "[A][C][F][B|A][D|A:C][E|B:F]"
learn.net
